{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper\n",
    "\n",
    "The purpose of this Jupyter Notebook is to scrape data from baseball-reference.com.\n",
    "We are interested in the **Team Standard Batting, Team Standard Pitching** and **Team Fielding** tables for seasons dating back to 2006, along with the **Standings** tables, found by following the links below and editing the year information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standings from 2006 to 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/leagues/MLB/2017-standings.shtml').read(),\"lxml\")\n",
    "\n",
    "tableStats = soup.find(id=\"all_expanded_standings_overall\")\n",
    "tableStats = tableStats.find_all(text=lambda text:isinstance(text, Comment))[0]\n",
    "tableStats = BeautifulSoup(tableStats, \"lxml\").find(class_=\"sortable stats_table\")\n",
    "\n",
    "#print(tableStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do it once. no headers.\n",
    "f = open('/Users/areevesman/Documents/br_scraping/output/output.txt', 'w')\n",
    "i = 1\n",
    "for row in tableStats.find_all('tr'):\n",
    "    #print(i)\n",
    "    col = row.find_all('td')\n",
    "    #print('len '+str(len(col)))\n",
    "    if len(col) > 0:\n",
    "        if i != 32:\n",
    "            \n",
    "            for j in range(0,22):\n",
    "                if j == 0:\n",
    "                    team = col[0].a.string.strip()\n",
    "                    f.write(team+',')\n",
    "                elif j > 0 and j < 21:\n",
    "                    entry = col[j].string.strip()\n",
    "                    f.write(entry + ',')\n",
    "                else:\n",
    "                    entry = col[j].string.strip()\n",
    "                    f.write(entry)\n",
    "            if i != 31:\n",
    "                f.write('\\n')\n",
    "    i = i + 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do it a bunch of times\n",
    "for year in range(2006,2018):\n",
    "    \n",
    "    #print(year)\n",
    "    \n",
    "    #read in html code for year url\n",
    "    soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/leagues/MLB/'+str(year)+'-standings.shtml').read(),\"lxml\")\n",
    "    \n",
    "    #get just the standings table\n",
    "    tableStats = soup.find(id=\"all_expanded_standings_overall\")\n",
    "    tableStats = tableStats.find_all(text=lambda text:isinstance(text, Comment))[0]\n",
    "    tableStats = BeautifulSoup(tableStats, \"lxml\").find(class_=\"sortable stats_table\")\n",
    "    \n",
    "    #make a file to store standings data for the year\n",
    "    f = open('/Users/areevesman/Documents/br_scraping/output/standings'+str(year)+'.csv', 'w')\n",
    "    #write header to file\n",
    "    f.write('team,league,games_played,wins,losses,win_loss_pct,r_per_game,ra_per_game,avg_run_diff,')\n",
    "    f.write('sos,srs,pythWL,luck,inter,home,road,exInn,one_run,vRHP,vLHP,over_500,under_500'+'\\n')\n",
    "    \n",
    "    #for each row, get entry for each column\n",
    "    i = 1\n",
    "    for row in tableStats.find_all('tr'):\n",
    "        \n",
    "        col = row.find_all('td')\n",
    "        if len(col) > 0:\n",
    "            if i != 32:\n",
    "\n",
    "                for j in range(0,22):\n",
    "                    if j == 0:\n",
    "                        team = col[0].a.string.strip()\n",
    "                        f.write(team+',')\n",
    "                    elif j > 0 and j < 21:\n",
    "                        entry = col[j].string.strip()\n",
    "                        f.write(entry + ',')\n",
    "                    else:\n",
    "                        entry = col[j].string.strip()\n",
    "                        f.write(entry)\n",
    "                if i != 31:\n",
    "                    f.write('\\n')\n",
    "        i = i + 1\n",
    "    #close the year file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Fielding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/leagues/MLB/'+str(year)+'.shtml').read(),\"lxml\")\n",
    "    \n",
    "#get just the standings table\n",
    "tableStats = soup.find(id=\"all_teams_standard_fielding\")\n",
    "tableStats = tableStats.find_all(text=lambda text:isinstance(text, Comment))[0]\n",
    "tableStats = BeautifulSoup(tableStats, \"lxml\").find(class_=\"sortable stats_table\")\n",
    "\n",
    "#print(tableStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do it a bunch of times\n",
    "for year in range(2006,2018):\n",
    "    \n",
    "    #print(year)\n",
    "    \n",
    "    #read in html code for year url\n",
    "    soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/leagues/MLB/'+str(year)+'.shtml').read(),\"lxml\")\n",
    "    \n",
    "    #get just the standings table\n",
    "    tableStats = soup.find(id=\"all_teams_standard_fielding\")\n",
    "    tableStats = tableStats.find_all(text=lambda text:isinstance(text, Comment))[0]\n",
    "    tableStats = BeautifulSoup(tableStats, \"lxml\").find(class_=\"sortable stats_table\")\n",
    "\n",
    "    #make a file to store standings data for the year\n",
    "    f = open('/Users/areevesman/Documents/br_scraping/output/fielding'+str(year)+'.csv', 'w')\n",
    "    #write header to file\n",
    "    f.write('team,num_fielders,field_ra_per_game,defEff,field_games_played,field_games_started,field_games_completed,')\n",
    "    f.write('field_innings_played,defensive_chances,putouts,assists,field_errors,double_plays,')\n",
    "    f.write('fielding_pct,field_rtot,field_rtot_per_year,field_rdrs,field_rdrs_per_year'+'\\n')\n",
    "    \n",
    "    #for each row, get entry for each column\n",
    "    i = 1\n",
    "    \n",
    "    for row in tableStats.find_all('tr')[1:]:\n",
    "        \n",
    "        if i != 31:\n",
    "\n",
    "            first_col = row.find(scope=\"row\")\n",
    "            team = first_col.a.string.strip()\n",
    "            f.write(team+',')\n",
    "\n",
    "            col = row.find_all('td')\n",
    "            if len(col) > 0:\n",
    "                if i != 31:\n",
    "\n",
    "                    for j in range(0,17):\n",
    "\n",
    "                        if j < 16:\n",
    "                            entry = col[j].string.strip()\n",
    "                            f.write(entry + ',')\n",
    "                        else:\n",
    "                            entry = col[j].string.strip()\n",
    "                            f.write(entry)\n",
    "                            \n",
    "                    if i != 30:\n",
    "                        f.write('\\n')\n",
    "            i = i + 1\n",
    "    #close the year file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Standard Pitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do it a bunch of times\n",
    "for year in range(2006,2018):\n",
    "    \n",
    "    #print(year)\n",
    "    \n",
    "    #read in html code for year url\n",
    "    soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/leagues/MLB/'+str(year)+'.shtml').read(),\"lxml\")\n",
    "    \n",
    "    #get just the standings table\n",
    "    tableStats = soup.find(id=\"all_teams_standard_pitching\")\n",
    "    tableStats = tableStats.find_all(text=lambda text:isinstance(text, Comment))[0]\n",
    "    tableStats = BeautifulSoup(tableStats, \"lxml\").find(class_=\"sortable stats_table\")\n",
    "\n",
    "    #make a file to store standings data for the year\n",
    "    f = open('/Users/areevesman/Documents/br_scraping/output/pitching'+str(year)+'.csv', 'w')\n",
    "    #write header to file\n",
    "    f.write('team,num_pitchers,pitching_avg_age,pitching_ra_per_game,pitching_wins,pitching_losses,')\n",
    "    f.write('pitching_win_loss_pct,ERA,pitching_games_played,pitching_games_started,pitching_games_finished,')\n",
    "    f.write('pitching_complete_game,team_shutouts,complete_game_shutouts,saves,innings_pitched,')\n",
    "    f.write('pitching_hits_allowed,pitching_ra,pitching_earned_ra,pitching_hr_allowed,pitching_bases_on_walks,')\n",
    "    f.write('pitching_intentional_bow,strikeouts,times_hit_by_pitch,balks,wild_pitches,batters_faced,')\n",
    "    f.write('ERAp,fielding_independent_pitching,whip,h9,hr9,bb9,so9,so_per_walk,pitching_runners_lob'+'\\n')\n",
    "    \n",
    "    #for each row, get entry for each column\n",
    "    i = 1\n",
    "    \n",
    "    for row in tableStats.find_all('tr')[1:]:\n",
    "        \n",
    "        if i != 31:\n",
    "\n",
    "            first_col = row.find(scope=\"row\")\n",
    "            team = first_col.a.string.strip()\n",
    "            f.write(team+',')\n",
    "\n",
    "            col = row.find_all('td')\n",
    "            if len(col) > 0:\n",
    "                if i != 31:\n",
    "\n",
    "                    for j in range(0,35):\n",
    "\n",
    "                        if j < 34:\n",
    "                            entry = col[j].string.strip()\n",
    "                            f.write(entry + ',')\n",
    "                        else:\n",
    "                            entry = col[j].string.strip()\n",
    "                            f.write(entry)\n",
    "                            \n",
    "                    if i != 30:\n",
    "                        f.write('\\n')\n",
    "            i = i + 1\n",
    "    #close the year file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Standard Batting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do it a bunch of times\n",
    "for year in range(2006,2018):\n",
    "    \n",
    "    #print(year)\n",
    "    \n",
    "    #read in html code for year url\n",
    "    soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/leagues/MLB/'+str(year)+'.shtml').read(),\"lxml\")\n",
    "    \n",
    "    #get just the standings table\n",
    "    tableStats = soup.find(\"table\",id=\"teams_standard_batting\")\n",
    "\n",
    "    #make a file to store standings data for the year\n",
    "    f = open('/Users/areevesman/Documents/br_scraping/output/batting'+str(year)+'.csv', 'w')\n",
    "    #write header to file\n",
    "    f.write('team,num_batters,batting_avg_age,batting_runs_per_game,batting_games_played,batting_plate_appearances,')\n",
    "    f.write('batting_at_bats,batting_runs,batting_hits,batting_doubles,batting_triples,')\n",
    "    f.write('batting_home_runs,batting_RBIs,batting_stolen_bases,batting_caught_stealing,')\n",
    "    f.write('batting_bases_on_walks,batting_strikeouts,batting_ave,OBP,SLG,OBS_plus_SLG,OPS_plus,')\n",
    "    f.write('batting_total_bases,batting_double_plays,batting_hit_by_pitch,sac_bunts,sac_flies,')\n",
    "    f.write('batting_intentional_bow,batting_runners_lob'+'\\n')\n",
    "    \n",
    "    #for each row, get entry for each column\n",
    "    i = 1\n",
    "    \n",
    "    for row in tableStats.find_all('tr')[1:]:\n",
    "        \n",
    "        if i != 31:\n",
    "\n",
    "            first_col = row.find(scope=\"row\")\n",
    "            team = first_col.a.string.strip()\n",
    "            f.write(team+',')\n",
    "\n",
    "            col = row.find_all('td')\n",
    "            if len(col) > 0:\n",
    "                if i != 31:\n",
    "\n",
    "                    for j in range(0,28):\n",
    "\n",
    "                        if j < 27:\n",
    "                            entry = col[j].string.strip()\n",
    "                            f.write(entry + ',')\n",
    "                        else:\n",
    "                            entry = col[j].string.strip()\n",
    "                            f.write(entry)\n",
    "                            \n",
    "                    if i != 30:\n",
    "                        f.write('\\n')\n",
    "            i = i + 1\n",
    "    #close the year file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #read in html code for year url\n",
    "    soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/leagues/MLB/'+str(year)+'.shtml').read(),\"lxml\")\n",
    "    \n",
    "    #get just the standings table\n",
    "    tableStats = soup.find(\"table\",id=\"teams_standard_batting\")\n",
    "    #print(tableStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

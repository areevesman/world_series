{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper\n",
    "\n",
    "The purpose of this Jupyter Notebook is to scrape data from baseball-reference.com.\n",
    "We are interested in the **Team Standard Batting, Team Standard Pitching** and **Team Fielding** tables for seasons dating back to 2006, along with the **Standings** tables, found by following the links below and editing the year information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standings from 2006 to 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/leagues/MLB/2017-standings.shtml').read(),\"lxml\")\n",
    "\n",
    "tableStats = soup.find(id=\"all_expanded_standings_overall\")\n",
    "tableStats = tableStats.find_all(text=lambda text:isinstance(text, Comment))[0]\n",
    "tableStats = BeautifulSoup(tableStats, \"lxml\").find(class_=\"sortable stats_table\")\n",
    "\n",
    "#print(tableStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do it once. no headers.\n",
    "f = open('/Users/areevesman/Documents/br_scraping/output/output.txt', 'w')\n",
    "i = 1\n",
    "for row in tableStats.find_all('tr'):\n",
    "    #print(i)\n",
    "    col = row.find_all('td')\n",
    "    #print('len '+str(len(col)))\n",
    "    if len(col) > 0:\n",
    "        if i != 32:\n",
    "            \n",
    "            for j in range(0,22):\n",
    "                if j == 0:\n",
    "                    team = col[0].a.string.strip()\n",
    "                    f.write(team+',')\n",
    "                elif j > 0 and j < 21:\n",
    "                    entry = col[j].string.strip()\n",
    "                    f.write(entry + ',')\n",
    "                else:\n",
    "                    entry = col[j].string.strip()\n",
    "                    f.write(entry)\n",
    "            if i != 31:\n",
    "                f.write('\\n')\n",
    "    i = i + 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do it a bunch of times\n",
    "for year in range(2006,2018):\n",
    "    \n",
    "    #print(year)\n",
    "    \n",
    "    #read in html code for year url\n",
    "    soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/leagues/MLB/'+str(year)+'-standings.shtml').read(),\"lxml\")\n",
    "    \n",
    "    #get just the standings table\n",
    "    tableStats = soup.find(id=\"all_expanded_standings_overall\")\n",
    "    tableStats = tableStats.find_all(text=lambda text:isinstance(text, Comment))[0]\n",
    "    tableStats = BeautifulSoup(tableStats, \"lxml\").find(class_=\"sortable stats_table\")\n",
    "    \n",
    "    #make a file to store standings data for the year\n",
    "    f = open('/Users/areevesman/Documents/br_scraping/output/standings'+str(year)+'.csv', 'w')\n",
    "    #write header to file\n",
    "    f.write('team,league,games_played,wins,losses,win_loss_pct,r_per_game,ra_per_game,avg_run_diff,')\n",
    "    f.write('sos,srs,pythWL,luck,inter,home,road,exInn,one_run,vRHP,vLHP,over_500,under_500'+'\\n')\n",
    "    \n",
    "    #for each row, get entry for each column\n",
    "    i = 1\n",
    "    for row in tableStats.find_all('tr'):\n",
    "        \n",
    "        col = row.find_all('td')\n",
    "        if len(col) > 0:\n",
    "            if i != 32:\n",
    "\n",
    "                for j in range(0,22):\n",
    "                    if j == 0:\n",
    "                        team = col[0].a.string.strip()\n",
    "                        f.write(team+',')\n",
    "                    elif j > 0 and j < 21:\n",
    "                        entry = col[j].string.strip()\n",
    "                        f.write(entry + ',')\n",
    "                    else:\n",
    "                        entry = col[j].string.strip()\n",
    "                        f.write(entry)\n",
    "                if i != 31:\n",
    "                    f.write('\\n')\n",
    "        i = i + 1\n",
    "    #close the year file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Fielding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/leagues/MLB/'+str(year)+'.shtml').read(),\"lxml\")\n",
    "    \n",
    "#get just the standings table\n",
    "tableStats = soup.find(id=\"all_teams_standard_fielding\")\n",
    "tableStats = tableStats.find_all(text=lambda text:isinstance(text, Comment))[0]\n",
    "tableStats = BeautifulSoup(tableStats, \"lxml\").find(class_=\"sortable stats_table\")\n",
    "\n",
    "#print(tableStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do it a bunch of times\n",
    "for year in range(2006,2018):\n",
    "    \n",
    "    #print(year)\n",
    "    \n",
    "    #read in html code for year url\n",
    "    soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/leagues/MLB/'+str(year)+'.shtml').read(),\"lxml\")\n",
    "    \n",
    "    #get just the standings table\n",
    "    tableStats = soup.find(id=\"all_teams_standard_fielding\")\n",
    "    tableStats = tableStats.find_all(text=lambda text:isinstance(text, Comment))[0]\n",
    "    tableStats = BeautifulSoup(tableStats, \"lxml\").find(class_=\"sortable stats_table\")\n",
    "\n",
    "    #make a file to store standings data for the year\n",
    "    f = open('/Users/areevesman/Documents/br_scraping/output/fielding'+str(year)+'.csv', 'w')\n",
    "    #write header to file\n",
    "    f.write('team,num_fielders,field_ra_per_game,defEff,field_games_played,field_games_started,field_games_completed,')\n",
    "    f.write('field_innings_played,defensive_chances,putouts,assists,field_errors,double_plays,')\n",
    "    f.write('fielding_pct,field_rtot,field_rtot_per_year,field_rdrs,field_rdrs_per_year'+'\\n')\n",
    "    \n",
    "    #for each row, get entry for each column\n",
    "    i = 1\n",
    "    \n",
    "    for row in tableStats.find_all('tr')[1:]:\n",
    "        \n",
    "        if i != 31:\n",
    "\n",
    "            first_col = row.find(scope=\"row\")\n",
    "            team = first_col.a.string.strip()\n",
    "            f.write(team+',')\n",
    "\n",
    "            col = row.find_all('td')\n",
    "            if len(col) > 0:\n",
    "                if i != 31:\n",
    "\n",
    "                    for j in range(0,17):\n",
    "\n",
    "                        if j < 16:\n",
    "                            entry = col[j].string.strip()\n",
    "                            f.write(entry + ',')\n",
    "                        else:\n",
    "                            entry = col[j].string.strip()\n",
    "                            f.write(entry)\n",
    "                            \n",
    "                    if i != 30:\n",
    "                        f.write('\\n')\n",
    "            i = i + 1\n",
    "    #close the year file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Standard Pitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do it a bunch of times\n",
    "for year in range(2006,2018):\n",
    "    \n",
    "    #print(year)\n",
    "    \n",
    "    #read in html code for year url\n",
    "    soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/leagues/MLB/'+str(year)+'.shtml').read(),\"lxml\")\n",
    "    \n",
    "    #get just the standings table\n",
    "    tableStats = soup.find(id=\"all_teams_standard_pitching\")\n",
    "    tableStats = tableStats.find_all(text=lambda text:isinstance(text, Comment))[0]\n",
    "    tableStats = BeautifulSoup(tableStats, \"lxml\").find(class_=\"sortable stats_table\")\n",
    "\n",
    "    #make a file to store standings data for the year\n",
    "    f = open('/Users/areevesman/Documents/br_scraping/output/pitching'+str(year)+'.csv', 'w')\n",
    "    #write header to file\n",
    "    f.write('team,num_pitchers,pitching_avg_age,pitching_ra_per_game,pitching_wins,pitching_losses,')\n",
    "    f.write('pitching_win_loss_pct,ERA,pitching_games_played,pitching_games_started,pitching_games_finished,')\n",
    "    f.write('pitching_complete_game,team_shutouts,complete_game_shutouts,saves,innings_pitched,')\n",
    "    f.write('pitching_hits_allowed,pitching_ra,pitching_earned_ra,pitching_hr_allowed,pitching_bases_on_walks,')\n",
    "    f.write('pitching_intentional_bow,strikeouts,times_hit_by_pitch,balks,wild_pitches,batters_faced,')\n",
    "    f.write('ERAp,fielding_independent_pitching,whip,h9,hr9,bb9,so9,so_per_walk,pitching_runners_lob'+'\\n')\n",
    "    \n",
    "    #for each row, get entry for each column\n",
    "    i = 1\n",
    "    \n",
    "    for row in tableStats.find_all('tr')[1:]:\n",
    "        \n",
    "        if i != 31:\n",
    "\n",
    "            first_col = row.find(scope=\"row\")\n",
    "            team = first_col.a.string.strip()\n",
    "            f.write(team+',')\n",
    "\n",
    "            col = row.find_all('td')\n",
    "            if len(col) > 0:\n",
    "                if i != 31:\n",
    "\n",
    "                    for j in range(0,35):\n",
    "\n",
    "                        if j < 34:\n",
    "                            entry = col[j].string.strip()\n",
    "                            f.write(entry + ',')\n",
    "                        else:\n",
    "                            entry = col[j].string.strip()\n",
    "                            f.write(entry)\n",
    "                            \n",
    "                    if i != 30:\n",
    "                        f.write('\\n')\n",
    "            i = i + 1\n",
    "    #close the year file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Standard Batting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do it a bunch of times\n",
    "for year in range(2006,2018):\n",
    "    \n",
    "    #print(year)\n",
    "    \n",
    "    #read in html code for year url\n",
    "    soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/leagues/MLB/'+str(year)+'.shtml').read(),\"lxml\")\n",
    "    \n",
    "    #get just the standings table\n",
    "    tableStats = soup.find(\"table\",id=\"teams_standard_batting\")\n",
    "\n",
    "    #make a file to store standings data for the year\n",
    "    f = open('/Users/areevesman/Documents/br_scraping/output/batting'+str(year)+'.csv', 'w')\n",
    "    #write header to file\n",
    "    f.write('team,num_batters,batting_avg_age,batting_runs_per_game,batting_games_played,batting_plate_appearances,')\n",
    "    f.write('batting_at_bats,batting_runs,batting_hits,batting_doubles,batting_triples,')\n",
    "    f.write('batting_home_runs,batting_RBIs,batting_stolen_bases,batting_caught_stealing,')\n",
    "    f.write('batting_bases_on_walks,batting_strikeouts,batting_ave,OBP,SLG,OBS_plus_SLG,OPS_plus,')\n",
    "    f.write('batting_total_bases,batting_double_plays,batting_hit_by_pitch,sac_bunts,sac_flies,')\n",
    "    f.write('batting_intentional_bow,batting_runners_lob'+'\\n')\n",
    "    \n",
    "    #for each row, get entry for each column\n",
    "    i = 1\n",
    "    \n",
    "    for row in tableStats.find_all('tr')[1:]:\n",
    "        \n",
    "        if i != 31:\n",
    "\n",
    "            first_col = row.find(scope=\"row\")\n",
    "            team = first_col.a.string.strip()\n",
    "            f.write(team+',')\n",
    "\n",
    "            col = row.find_all('td')\n",
    "            if len(col) > 0:\n",
    "                if i != 31:\n",
    "\n",
    "                    for j in range(0,28):\n",
    "\n",
    "                        if j < 27:\n",
    "                            entry = col[j].string.strip()\n",
    "                            f.write(entry + ',')\n",
    "                        else:\n",
    "                            entry = col[j].string.strip()\n",
    "                            f.write(entry)\n",
    "                            \n",
    "                    if i != 30:\n",
    "                        f.write('\\n')\n",
    "            i = i + 1\n",
    "    #close the year file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Franchises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 8] nodename nor servname provided, or not known>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1318\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 936\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-362410429157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#read in html code for year url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.baseball-reference.com/teams/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#get just the standings table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtableStats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"table\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"teams_active\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1361\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 8] nodename nor servname provided, or not known>"
     ]
    }
   ],
   "source": [
    "#read in html code for year url\n",
    "soup = BeautifulSoup(urllib.request.urlopen('https://www.baseball-reference.com/teams/').read(),\"lxml\")\n",
    "\n",
    "#get just the standings table\n",
    "tableStats = soup.find(\"table\", id=\"teams_active\").tbody\n",
    "\n",
    "#make a file to store standings data for the year\n",
    "#f = open('/Users/areevesman/Documents/br_scraping/output/active_franchises.csv', 'w')\n",
    "\n",
    "\n",
    "#for each row, get entry for each column\n",
    "# i = 1\n",
    "\n",
    "# for row in tableStats.find_all('tr')[1:]:\n",
    "\n",
    "#     if i != 31:\n",
    "\n",
    "#         first_col = row.find(scope=\"row\")\n",
    "#         team = first_col.a.string.strip()\n",
    "#         f.write(team+',')\n",
    "\n",
    "#         col = row.find_all('td')\n",
    "#         if len(col) > 0:\n",
    "#             if i != 31:\n",
    "\n",
    "#                 for j in range(0,28):\n",
    "\n",
    "#                     if j < 27:\n",
    "#                         entry = col[j].string.strip()\n",
    "#                         f.write(entry + ',')\n",
    "#                     else:\n",
    "#                         entry = col[j].string.strip()\n",
    "#                         f.write(entry)\n",
    "\n",
    "#                 if i != 30:\n",
    "#                     f.write('\\n')\n",
    "#         i = i + 1\n",
    "# #close the year file\n",
    "# f.close()\n",
    "\n",
    "#tableStats\n",
    "\n",
    "\n",
    "for row in tableStats.find_all('tr')[1:]:\n",
    "    \n",
    "    col = row.find_all('td')[0]\n",
    "    \n",
    "    if type(col.a.string.strip()) != 'NoneType':\n",
    "        print(col.a.string.strip())\n",
    "    \n",
    "        #print(row)\n",
    "        print(\"........\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
